# Bangkok AQI Pipeline

[![CI](https://github.com/potangpa-sudo/bangkok-aqi-pipeline/actions/workflows/ci.yml/badge.svg)](https://github.com/potangpa-sudo/bangkok-aqi-pipeline/actions/workflows/ci.yml)
[![Deploy](https://github.com/potangpa-sudo/bangkok-aqi-pipeline/actions/workflows/deploy.yml/badge.svg)](https://github.com/potangpa-sudo/bangkok-aqi-pipeline/actions/workflows/deploy.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Terraform](https://img.shields.io/badge/terraform-1.5.0+-purple.svg)](https://www.terraform.io/)

> **Production-Grade Data Engineering Pipeline**: End-to-end cloud data pipeline for real-time air quality monitoring in Bangkok

## üéØ Overview

This project demonstrates a complete data engineering pipeline that ingests, processes, and visualizes air quality data for Bangkok. Built with modern cloud technologies and best practices, it showcases production-ready data engineering skills.

### Key Features

- **üåê Real-time Data Ingestion**: Automated hourly data collection from Open-Meteo APIs
- **‚òÅÔ∏è Cloud-Native Architecture**: Built on Google Cloud Platform with serverless components
- **üîÑ Event-Driven Processing**: Pub/Sub messaging and Airflow orchestration
- **üìä Data Warehousing**: BigQuery with partitioning and clustering for optimal performance
- **üõ†Ô∏è Infrastructure as Code**: Complete Terraform deployment with reusable modules
- **üìà Interactive Dashboard**: Streamlit-based analytics dashboard
- **‚úÖ Data Quality**: Comprehensive testing with dbt and automated validation
- **üöÄ CI/CD Pipeline**: Automated testing, building, and deployment

## üèóÔ∏è Architecture

```
Open-Meteo API ‚Üí Cloud Run (Ingestor) ‚Üí GCS (Raw) ‚Üí Pub/Sub
                                                        ‚Üì
                                          Cloud Composer (Airflow)
                                                        ‚Üì
                                  Dataproc Spark (Cleanse) ‚Üí BigQuery (Staging)
                                                                      ‚Üì
                                                        dbt (Transform) ‚Üí BigQuery (Marts)
                                                                                  ‚Üì
                                                                Cloud Run (Dashboard)
```

**[See detailed architecture documentation ‚Üí](docs/architecture.md)**

## üìÅ Project Structure

```
bangkok-aqi-pipeline/
‚îú‚îÄ‚îÄ infra/terraform/              # Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.tf                   # Main Terraform configuration
‚îÇ   ‚îú‚îÄ‚îÄ modules/                  # Reusable Terraform modules
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ src/ingestor/                 # Cloud Run ingestor service
‚îÇ   ‚îú‚îÄ‚îÄ app.py                    # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ clients.py                # GCS & Pub/Sub clients
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                # Container configuration
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ airflow/dags/                 # Airflow DAGs
‚îÇ   ‚îî‚îÄ‚îÄ aqi_hourly.py             # Hourly pipeline orchestration
‚îú‚îÄ‚îÄ spark/                        # PySpark cleansing jobs
‚îÇ   ‚îú‚îÄ‚îÄ cleanse.py                # Main Spark job
‚îÇ   ‚îú‚îÄ‚îÄ job_config.json           # Dataproc configuration
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ dbt/                          # dbt transformation project
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # SQL models
‚îÇ   ‚îú‚îÄ‚îÄ dbt_project.yml
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ app/                          # Streamlit dashboard
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_bq.py           # BigQuery-backed dashboard
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .github/workflows/            # CI/CD pipelines
‚îÇ   ‚îú‚îÄ‚îÄ ci.yml                    # Continuous integration
‚îÇ   ‚îî‚îÄ‚îÄ deploy.yml                # Deployment pipeline
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ architecture.md           # Architecture & runbook
‚îî‚îÄ‚îÄ README.md                     # This file
```

## üöÄ Quick Start

### Prerequisites

- GCP Project with billing enabled
- `gcloud` CLI authenticated
- Terraform >= 1.5.0
- Python 3.11+
- Docker (for local testing)

### 1. Clone and Configure

```bash
git clone https://github.com/potangpa-sudo/bangkok-aqi-pipeline.git
cd bangkok-aqi-pipeline

# Copy and configure environment
cp .env.example .env
# Edit .env with your GCP project details
```

### 2. Deploy Infrastructure

```bash
cd infra/terraform
cp terraform.tfvars.example terraform.tfvars
# Edit terraform.tfvars with your configuration

terraform init
terraform plan
terraform apply
```

### 3. Deploy Services

```bash
# Build and deploy services
cd ../../src/ingestor
gcloud builds submit --tag gcr.io/${PROJECT_ID}/aqi-ingestor
gcloud run deploy aqi-ingestor --image gcr.io/${PROJECT_ID}/aqi-ingestor

cd ../../app
gcloud builds submit --tag gcr.io/${PROJECT_ID}/aqi-dashboard
gcloud run deploy aqi-dashboard --image gcr.io/${PROJECT_ID}/aqi-dashboard
```

### 4. Run Pipeline

```bash
# Trigger manual ingestion
INGESTOR_URL=$(terraform output -raw ingestor_service_url)
curl -X POST "${INGESTOR_URL}/ingest/hourly?city=Bangkok"

# View dashboard
DASHBOARD_URL=$(terraform output -raw dashboard_service_url)
open ${DASHBOARD_URL}
```

**[See complete deployment guide ‚Üí](DEPLOYMENT.md)**

## üíª Local Development

The project includes a local development mode for testing and development:

```bash
# Setup local environment
make setup

# Run local pipeline
make run

# Run tests
make test

# Launch local dashboard
make dashboard
```

## üìä Data Model

The pipeline follows a layered data architecture:

1. **Raw Layer**: Unprocessed API responses stored in GCS
2. **Staging Layer**: Cleaned and validated data in BigQuery
3. **Fact Layer**: Combined hourly observations
4. **Mart Layer**: Daily aggregates for analytics

## üß™ Testing

### Automated Testing

- **Python**: Unit tests with pytest
- **SQL**: dbt model testing
- **Terraform**: Configuration validation
- **Docker**: Container builds

### Data Quality

- Schema validation
- Completeness checks
- Freshness monitoring
- Automated alerts

## üìà Monitoring & Observability

- **Cloud Monitoring**: Infrastructure metrics and uptime
- **Cloud Logging**: Centralized logs from all services
- **Airflow UI**: DAG runs and task execution
- **BigQuery**: Query performance and data freshness

## üí∞ Cost Management

**Estimated monthly cost: ~$105 USD**

- Cloud Composer (Small): $75
- Dataproc Serverless: $15
- BigQuery: $10
- GCS: $3
- Cloud Run: $1
- Other: $1

## üîí Security

- All secrets managed in Secret Manager
- Least-privilege IAM roles per service
- Data encrypted at rest and in transit
- Audit logging enabled

## üìö Documentation

- **[Architecture & Runbook](docs/architecture.md)** - System design and operations
- **[Deployment Guide](DEPLOYMENT.md)** - Step-by-step deployment instructions
- **[Terraform README](infra/terraform/README.md)** - Infrastructure deployment
- **[Contributing Guide](CONTRIBUTING.md)** - How to contribute to the project

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes with tests
4. Commit using conventional commits (`git commit -m 'feat: add amazing feature'`)
5. Push to your branch (`git push origin feature/amazing-feature`)
6. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- [Open-Meteo](https://open-meteo.com/) for providing free weather and AQI APIs
- [Google Cloud Platform](https://cloud.google.com/) for cloud infrastructure
- [dbt Labs](https://www.getdbt.com/) for the transformation framework
- [Apache Airflow](https://airflow.apache.org/) for workflow orchestration
- [Terraform](https://www.terraform.io/) for infrastructure-as-code

## üìû Support

- **Issues**: [Report a bug](https://github.com/potangpa-sudo/bangkok-aqi-pipeline/issues/new?template=bug_report.md)
- **Feature Requests**: [Request a feature](https://github.com/potangpa-sudo/bangkok-aqi-pipeline/issues/new?template=feature_request.md)
- **Discussions**: [GitHub Discussions](https://github.com/potangpa-sudo/bangkok-aqi-pipeline/discussions)

---

**Built with ‚ù§Ô∏è for the data engineering community**